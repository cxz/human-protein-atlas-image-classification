{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "TRAIN_PATH = '../input/train'\n",
    "TRAIN_FULL_PATH = '/kaggle2/hpaic/train-full'\n",
    "\n",
    "TEST_PATH = '../input/test'\n",
    "TEST_FULL_PATH = '/kaggle2/hpaic/test-full'\n",
    "\n",
    "PATCH_SIZE = 96 # 512/6 -- 512/4\n",
    "TARGET_PATCH_SIZE = 224\n",
    "STRIDE = 32\n",
    "MAX_PATCHES = 100 # max patches from each sample\n",
    "MAX_TRAIN_IMAGES_PER_CLASS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_512_green(image_id, mode='train'):\n",
    "    base_path = TRAIN_PATH if mode == 'train' else TEST_PATH\n",
    "    img = None\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    path = os.path.join(base_path, f\"{image_id}_green.png\")\n",
    "    img_ = cv2.imread(str(path), flags).astype(np.float32) / 255.\n",
    "    return img_\n",
    "\n",
    "def build_candidates(train_ids):    \n",
    "    candidates = []    \n",
    "    \n",
    "    for image_id in tqdm(train_ids):\n",
    "        # load 512 image, find candidate patches\n",
    "        img = _load_512_green(image_id)\n",
    "        total = np.sum(img) \n",
    "        \n",
    "        size = 512\n",
    "        patch_size = PATCH_SIZE \n",
    "        stride = STRIDE\n",
    "        \n",
    "        max_patches = STRIDE # maximum patches per image        \n",
    "        patches = {}\n",
    "        for j in range(0, size - patch_size, stride):\n",
    "            for i in range(0, size - patch_size, stride):\n",
    "                s = np.sum(img[j:j+patch_size, i:i+patch_size])                \n",
    "                if s > 0:\n",
    "                    patches[(j, i)] = s \n",
    "        \n",
    "        # order patches by sum of pixels\n",
    "        for patch, s in sorted(patches.items(), key=operator.itemgetter(1), reverse=True)[:max_patches]:\n",
    "            patch_j, patch_i = patch\n",
    "            if s > 0:\n",
    "                candidates.append((image_id, patch_j, patch_i))\n",
    "        \n",
    "    return candidates\n",
    "\n",
    "def build_sample():\n",
    "    IMAGES_PER_CLASS = MAX_TRAIN_IMAGES_PER_CLASS # TODO: remove this later\n",
    "    \n",
    "    df = pd.read_csv('../input/train.csv')\n",
    "    \n",
    "    train_ids = []\n",
    "    \n",
    "    for klazz in range(28):\n",
    "        klazz_df = df[df.Target==str(klazz)]\n",
    "        sample_size = min(IMAGES_PER_CLASS, len(klazz_df))        \n",
    "        # print(klazz, sample_size)\n",
    "        if sample_size > 0:\n",
    "            train_ids.extend(klazz_df.sample(n=sample_size).Id.values)  \n",
    "        \n",
    "    return train_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_ids = build_sample()\n",
    "#patch_ids = build_candidates(image_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_samples_with_multiple_labels():\n",
    "    df = pd.read_csv('../input/train.csv')\n",
    "    return [image_id for image_id, label in df[['Id', 'Target']].values if len(label.split(' ')) > 1]\n",
    "\n",
    "def save_multilabel_csv(patch_ids):\n",
    "    df = pd.read_csv('../input/train.csv')\n",
    "    labels = df.set_index('Id').to_dict()['Target']\n",
    "    rows = []\n",
    "    for image_id, patch_j, patch_i in patch_ids:\n",
    "        label = labels[image_id]\n",
    "        rows.append([image_id, patch_j, patch_i, label])\n",
    "        \n",
    "    df2 = pd.DataFrame(rows, columns=['image_id', 'patch_j', 'patch_i', 'target'])\n",
    "    df2.to_csv(os.path.join('../data/multilabelpatches.csv'), index=False)\n",
    "\n",
    "    \n",
    "multilabel_image_ids = build_samples_with_multiple_labels()\n",
    "multilabel_patch_ids = build_candidates(multilabel_image_ids)\n",
    "save_multilabel_csv(multilabel_patch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_candidates(test_ids):    \n",
    "    candidates = []    \n",
    "    \n",
    "    for image_id in tqdm(test_ids):\n",
    "        # load 512 image, find candidate patches\n",
    "        img = _load_512_green(image_id, mode='test')\n",
    "        total = np.sum(img) \n",
    "        \n",
    "        size = 512\n",
    "        patch_size = PATCH_SIZE\n",
    "        stride = STRIDE\n",
    "        \n",
    "        max_patches = 100\n",
    "        patches = {}\n",
    "        for j in range(0, size - patch_size, stride):\n",
    "            for i in range(0, size - patch_size, stride):\n",
    "                s = np.sum(img[j:j+patch_size, i:i+patch_size])                \n",
    "                if s > 0:\n",
    "                    patches[(j, i)] = s \n",
    "        \n",
    "        # order patches by sum of pixels\n",
    "        for patch, s in sorted(patches.items(), key=operator.itemgetter(1), reverse=True)[:max_patches]:\n",
    "            patch_j, patch_i = patch\n",
    "            if s > 0:\n",
    "                candidates.append((image_id, patch_j, patch_i))\n",
    "        \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test patches\n",
    "test_image_ids = pd.read_csv('../input/sample_submission.csv').Id.values\n",
    "test_patch_ids = build_test_candidates(test_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# build fold.csv having patch_ids for single-class samples\n",
    "def build_folds(patch_ids):\n",
    "    df = pd.read_csv('../input/train.csv')\n",
    "    labels = df.set_index('Id').to_dict()['Target']\n",
    "    rows = []\n",
    "    for image_id, patch_j, patch_i in patch_ids:\n",
    "        label = labels[image_id]\n",
    "        rows.append([image_id, patch_j, patch_i, label])\n",
    "        \n",
    "    df2 = pd.DataFrame(rows, columns=['image_id', 'patch_j', 'patch_i', 'target'])\n",
    "    df2['fold'] = 0\n",
    "    n_fold = 5\n",
    "    skf = StratifiedKFold(n_splits=n_fold, random_state=123, shuffle=True)\n",
    "    for fold_no, (train_idx, test_idx) in enumerate(skf.split(range(len(rows)), df2.target)):\n",
    "        df2.loc[test_idx, 'fold'] = fold_no    \n",
    "        \n",
    "    df2['idx'] = range(len(df2))\n",
    "    df2.to_csv(os.path.join('../data/singleclasspatchesfolds.csv'), index=False)\n",
    "\n",
    "# generate singleclasspatchesfolds.csv    \n",
    "build_folds(patch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_csv(test_patch_ids):\n",
    "    df = pd.DataFrame(test_patch_ids, columns=['image_id', 'patch_j', 'patch_i'])    \n",
    "    df['idx'] = range(len(df))\n",
    "    df.to_csv(os.path.join('../data/singleclasspatchestest.csv'), index=False)\n",
    "\n",
    "# generate singleclasspatchestest.csv    \n",
    "build_test_csv(test_patch_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_patch_from_png(image_id, patch_j, patch_i, patch_size, mode='train'):\n",
    "    base_path = TEST_PATH if mode == 'test' else TRAIN_PATH\n",
    "    kinds = ['red', 'blue', 'yellow', 'green']\n",
    "    img = None\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    img = np.zeros((patch_size, patch_size, len(kinds)), np.float32)\n",
    "    for idx, kind in enumerate(kinds):\n",
    "        path = os.path.join(base_path, f\"{image_id}_{kind}.png\")\n",
    "        img_ = cv2.imread(str(path), flags).astype(np.float32) / 255.\n",
    "        img[:, :, idx] = img_[patch_j:patch_j+patch_size, patch_i:patch_i+patch_size]        \n",
    "    return img\n",
    "\n",
    "def _load_tif(image_id, mode='train'):\n",
    "    base_path = TEST_FULL_PATH if mode == 'test' else TRAIN_FULL_PATH\n",
    "    kinds = ['red', 'blue', 'yellow', 'green']\n",
    "    img = None\n",
    "    flags = cv2.IMREAD_GRAYSCALE\n",
    "    img = None\n",
    "    for idx, kind in enumerate(kinds):\n",
    "        path = os.path.join(base_path, f\"{image_id}_{kind}.tif\")\n",
    "        img_ = cv2.imread(str(path), flags).astype(np.float32) / 255.\n",
    "        if img is None:\n",
    "            # we don't know original size, could be 512, or resized during preprocessing to a smaler size.\n",
    "            original_size = img_.shape[0]\n",
    "            img = np.zeros((original_size, original_size, len(kinds)), np.float32)\n",
    "        img[:, :, idx] = img_\n",
    "    return img\n",
    "\n",
    "def _load_patch_from_tif(tiff_img, patch_j, patch_i, patch_size, size):\n",
    "    \"\"\" load patch from tiff given patch coordinates. coordinates are given wrt png file.\n",
    "    \"\"\"            \n",
    "    img_size_ = tiff_img.shape[0]\n",
    "    factor = img_size_ / 512.\n",
    "    patch_j_ = int(patch_j * factor)\n",
    "    patch_i_ = int(patch_i * factor)\n",
    "    patch_size_ = int(patch_size * factor)\n",
    "    return cv2.resize(tiff_img[patch_j_:patch_j_+patch_size_, patch_i_:patch_i_+patch_size_, :], (size, size))    \n",
    "    \n",
    "\n",
    "def save_train_patches():\n",
    "    df = pd.read_csv('../data/singleclasspatchesfolds.csv')\n",
    "    \n",
    "    patch_size = PATCH_SIZE\n",
    "    size = TARGET_PATCH_SIZE\n",
    "    out_path = f'/kaggle2/hpaic-cache'\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    f = h5py.File(os.path.join(out_path, f'train_{patch_size}.h5'), 'w')\n",
    "    imgs = f.create_dataset('train', (len(df), size, size, 4), dtype=np.uint8)\n",
    "    \n",
    "    for image_id, patches in tqdm(df[['idx', 'image_id', 'patch_j', 'patch_i']].groupby('image_id')):\n",
    "        tiff_img = _load_tif(image_id)\n",
    "        for idx, patch_j, patch_i in patches[['idx', 'patch_j', 'patch_i']].values:\n",
    "            patch = _load_patch_from_tif(tiff_img, patch_j, patch_i, patch_size, size)\n",
    "            imgs[idx] = patch * 255\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_train_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_patches():\n",
    "    patch_size = PATCH_SIZE\n",
    "    size = TARGET_PATCH_SIZE\n",
    "    out_path = f'/kaggle2/hpaic-cache'\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    \n",
    "    df = pd.read_csv('../data/singleclasspatchestest.csv')\n",
    "    print('rows: ', len(df))\n",
    "    \n",
    "    f = h5py.File(os.path.join(out_path, f'test_{patch_size}.h5'), 'w')\n",
    "    imgs = f.create_dataset('test', (len(df), size, size, 4), dtype=np.uint8)\n",
    "            \n",
    "    for image_id, patches in tqdm(df[['idx', 'image_id', 'patch_j', 'patch_i']].groupby('image_id')):\n",
    "        tiff_img = _load_tif(image_id, mode='test')\n",
    "        for idx, patch_j, patch_i in patches[['idx', 'patch_j', 'patch_i']].values:\n",
    "            patch = _load_patch_from_tif(tiff_img, patch_j, patch_i, patch_size, size)\n",
    "            imgs[idx] = patch * 255\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_test_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_multilabel_train_patches():\n",
    "    df = pd.read_csv('../data/multilabelpatches.csv')\n",
    "    \n",
    "    patch_size = PATCH_SIZE\n",
    "    size = TARGET_PATCH_SIZE\n",
    "    out_path = f'/kaggle2/hpaic-cache'\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    f = h5py.File(os.path.join(out_path, f'train_multilabel_{patch_size}.h5'), 'w')\n",
    "    imgs = f.create_dataset('train', (len(df), size, size, 4), dtype=np.uint8)\n",
    "    idx = 0\n",
    "    for image_id, patches in tqdm(df[['image_id', 'patch_j', 'patch_i']].groupby('image_id')):\n",
    "        tiff_img = _load_tif(image_id)\n",
    "        for patch_j, patch_i in patches[['patch_j', 'patch_i']].values:\n",
    "            patch = _load_patch_from_tif(tiff_img, patch_j, patch_i, patch_size, size)\n",
    "            imgs[idx] = patch * 255\n",
    "            idx += 1\n",
    "    f.close()\n",
    "    \n",
    "save_multilabel_train_patches()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [transforms.ToTensor()(load_patch_from_png(image_id, patch_j, patch_i, 96)[:, :, :3]) for image_id, patch_j, patch_i in patches]\n",
    "x2 = [transforms.ToTensor()(load_patch_from_tif(image_id, patch_j, patch_i, 96, 224)[:, :, :3]) for image_id, patch_j, patch_i in patches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "show(make_grid(x2, padding=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "show(make_grid(x, padding=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id, patch_j, patch_i = patches[0]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(load_patch_from_png(image_id, patch_j, patch_i, 96)[:,:,:3])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(load_patch_from_tif(image_id, patch_j, patch_i, 96, 224)[:,:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
